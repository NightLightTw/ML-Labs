{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import IPython.display as display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os, random\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========== Download Dataset ==========\n",
    "# #!pip install -U gdown\n",
    "# import gdown, zipfile\n",
    "# file_id = \"1eyrNGFlM83pf-TETo30Cvjm7kYuCFAqu\" # <-- from your real zip file link\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"dataset.zip\", quiet=False)\n",
    "# with zipfile.ZipFile(\"dataset.zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========Dataset Preparation ==========\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_WIDTH=128\n",
    "BATCH_SIZE=64\n",
    "def get_pathframe(path):\n",
    "    '''\n",
    "    Get all the images paths and its corresponding labels\n",
    "    Store them in pandas dataframe\n",
    "    '''\n",
    "    filenames = os.listdir(path)\n",
    "    categories = []\n",
    "    paths=[]\n",
    "    for filename in filenames:\n",
    "        paths.append(path+filename)\n",
    "        category = filename.split('.')[0]\n",
    "        if category == 'dog':\n",
    "            categories.append(1)\n",
    "        else:\n",
    "            categories.append(0)\n",
    "    df= pd.DataFrame({\n",
    "        'filename': filenames,\n",
    "        'category': categories,\n",
    "        'paths':paths\n",
    "    })\n",
    "    return df\n",
    "df=get_pathframe(\"dataset/dataset/\")\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd8ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Convert to tensor ==========\n",
    "def load_and_preprocess_image(path):\n",
    "    '''\n",
    "    Load each image and resize it to desired shape\n",
    "    '''\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMAGE_WIDTH, IMAGE_HEIGHT])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "def convert_to_tensor(df):\n",
    "    '''\n",
    "    Convert each data and labels to tensor\n",
    "    '''\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(df['paths'])\n",
    "    image_ds = path_ds.map(load_and_preprocess_image)\n",
    "    # onehot_label=tf.one_hot(tf.cast(df['category'], tf.int64),2) if using softmax\n",
    "    onehot_label=tf.cast(df['category'], tf.int64)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(onehot_label)\n",
    "    return image_ds,label_ds\n",
    "\n",
    "X,Y=convert_to_tensor(df)\n",
    "print(\"Shape of X in data:\", X)\n",
    "print(\"Shape of Y in data:\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeadcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Images\n",
    "dataset=tf.data.Dataset.zip((X,Y)).shuffle(buffer_size=2000, seed=0)\n",
    "dataset_train=dataset.take(22500)\n",
    "dataset_test=dataset.skip(22500)\n",
    "dataset_train=dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_test=dataset_test.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_train\n",
    "\n",
    "def plotimages(imagesls):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for image,ax in zip(imagesls, axes):\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        \n",
    "imagesls=[]\n",
    "for n, image in enumerate(X.take(5)):\n",
    "    imagesls.append(image) \n",
    "plotimages(imagesls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Design\n",
    "def My_CNNmodel():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Conv2D(8, (3, 3), padding='same',activation='relu',\n",
    "    input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(16, (3, 3),\n",
    "    padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3),\n",
    "    padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3),\n",
    "    padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    opt=tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy', # loss='categorical_crossentropy' if softmax\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model=My_CNNmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b892e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "#You can adjust the epochs to get better training results, be aware with overfitting\n",
    "hist=model.fit(dataset_train, epochs=2, validation_data=dataset_test)\n",
    "#Save trained model\n",
    "model.save(\"weights/313605013.keras\") #Save the model with your student ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot training results\n",
    "def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axs[0].plot(range(1, len(model_history.history[acc]) + 1),\n",
    "    model_history.history[acc])\n",
    "    axs[0].plot(range(1, len(model_history.history[val_acc]) + 1),\n",
    "    model_history.history[val_acc])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1, len(model_history.history[acc]) + 1))\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    \n",
    "    # Loss plot\n",
    "    axs[1].plot(range(1, len(model_history.history['loss']) + 1),\n",
    "    model_history.history['loss'])\n",
    "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1),\n",
    "    model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1))\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(dataset_test)\n",
    "print(\"Test: accuracy = %f ; loss = %f \" % (accuracy, loss))\n",
    "\n",
    "# Predict values\n",
    "y_pred = model.predict(dataset_test)\n",
    "y_p = np.where(y_pred > 0.5, 1, 0) # for binary classification\n",
    "\n",
    "# Extract ground truth labels\n",
    "test_data = dataset_test.unbatch()\n",
    "y_g = []\n",
    "for image, label in test_data:\n",
    "    y_g.append(label.numpy())\n",
    "    \n",
    "# Convert to flat array if needed\n",
    "y_g = np.array(y_g).flatten()\n",
    "y_p = y_p.flatten()\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_g, y_p)\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Blues\",\n",
    "linecolor=\"gray\", fmt='.1f', ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2121a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a classification report\n",
    "report = classification_report(y_g, y_p, target_names=['0','1'])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
